// Подключаем стандартную библиотеку для ввода и вывода данных
#include <iostream>

// Подключаем стандартную библиотеку для работы с динамическими массивами
#include <vector>

// Подключаем библиотеку для генерации псевдослучайных чисел
#include <random>

// Подключаем заголовочный файл CUDA Runtime API
#include <cuda_runtime.h>

// Подключаем заголовочный файл с объявлениями GPU-функций
#include "memory_ops.h"

// Определяем макрос для проверки корректности выполнения вызовов CUDA API
#define CUDA_CHECK(x) do { cudaError_t err = x; if (err != cudaSuccess) { /* начало проверки */ \
/* Выводим сообщение об ошибке CUDA в стандартный поток ошибок */ std::cerr << "CUDA error: " << cudaGetErrorString(err) << std::endl; \
/* Принудительно завершаем выполнение программы при возникновении ошибки */ exit(1); } } while(0)

// Определяем точку входа в программу
int main()
{
    // Создаем вектор размеров массивов для проведения серии экспериментов
    std::vector<int> sizes = {10000, 100000, 1000000};

    // Инициализируем генератор псевдослучайных чисел с фиксированным зерном
    std::mt19937 rng(42);

    // Задаем равномерное распределение вещественных чисел в диапазоне от 0 до 1
    std::uniform_real_distribution<float> dist(0.0f, 1.0f);

    // Запускаем цикл по всем заданным размерам массивов
    for (int N : sizes)
    {
        // Выводим в консоль текущий размер массива
        std::cout << "Array size: " << N << std::endl;

        // Создаем вектор на стороне CPU для хранения исходных данных
        std::vector<float> h(N);

        // Запускаем цикл заполнения массива псевдослучайными числами
        for (int i = 0; i < N; ++i)

            // Записываем в текущий элемент массива случайное число из заданного распределения
            h[i] = dist(rng);

        // Объявляем указатель на массив в памяти GPU
        float* d;

        // Выделяем память на GPU под массив из N элементов типа float
        CUDA_CHECK(cudaMalloc(&d, N * sizeof(float)));

        // Копируем данные из памяти CPU в память GPU
        CUDA_CHECK(cudaMemcpy(d, h.data(), N * sizeof(float), cudaMemcpyHostToDevice));

        // Объявляем переменные для хранения результатов редукции
        float sum1, sum2;

        // Объявляем переменные для хранения времени выполнения редукции
        float t_global, t_shared;

        // Вызываем функцию редукции суммы с использованием только глобальной памяти GPU
        gpu_reduce_global(d, N, sum1, t_global);

        // Вызываем функцию редукции суммы с использованием разделяемой памяти GPU
        gpu_reduce_shared(d, N, sum2, t_shared);

        // Выводим в консоль время выполнения редукции с использованием глобальной памяти
        std::cout << "GPU Reduce GLOBAL: " << t_global << " ms" << std::endl;

        // Выводим в консоль время выполнения редукции с использованием разделяемой памяти
        std::cout << "GPU Reduce SHARED: " << t_shared << " ms" << std::endl;

        // Объявляем переменные для хранения времени локальной сортировки и слияния
        float t_local, t_merge;

        // Вызываем функцию сортировки с использованием локальной памяти и слияния через shared memory
        gpu_sort_with_local_and_shared(d, N, t_local, t_merge);

        // Выводим в консоль время выполнения локальной пузырьковой сортировки
        std::cout << "GPU Local Bubble Sort: " << t_local << " ms" << std::endl;

        // Выводим в консоль время выполнения этапа слияния с использованием разделяемой памяти
        std::cout << "GPU Merge (shared): " << t_merge << " ms" << std::endl;

        // Выводим пустую строку для визуального разделения результатов экспериментов
        std::cout << std::endl;

        // Освобождаем ранее выделенную память на GPU
        cudaFree(d);
    }

    // Возвращаем код успешного завершения программы
    return 0;
}

