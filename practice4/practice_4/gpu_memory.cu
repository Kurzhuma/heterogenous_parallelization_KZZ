// Подключаем заголовочный файл CUDA Runtime API
#include <cuda_runtime.h>

// Подключаем стандартную библиотеку для ввода и вывода данных
#include <iostream>

// Подключаем заголовочный файл с объявлениями функций работы с памятью и GPU
#include "memory_ops.h"

// Определяем макрос для проверки корректности выполнения вызовов CUDA API (многострочный макрос оформляется без разрыва комментариями)
#define CUDA_CHECK(x) do { cudaError_t err = x; if (err != cudaSuccess) { \
    std::cerr << "CUDA error: " << cudaGetErrorString(err) << std::endl; exit(1); } } while(0)

// =====================================
// Раздел: Редукция с использованием только глобальной памяти (через atomic)
// =====================================

// Объявляем CUDA-ядро для редукции суммы с использованием только глобальной памяти
__global__ void reduce_global_kernel(const float* in, float* out, int n)
{
    // Вычисляем глобальный индекс текущего потока
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    // Проверяем, что индекс не выходит за пределы массива
    if (idx < n)
        // Атомарно прибавляем значение текущего элемента к общей сумме в глобальной памяти
        atomicAdd(out, in[idx]);
}

// =====================================
// Раздел: Редукция с использованием разделяемой памяти (shared)
// =====================================

// Объявляем CUDA-ядро для редукции суммы с использованием shared memory
__global__ void reduce_shared_kernel(const float* in, float* out, int n)
{
    // Объявляем массив в разделяемой памяти для хранения частичных сумм блока
    __shared__ float sdata[256];

    // Получаем локальный индекс потока в блоке
    int tid = threadIdx.x;
    // Вычисляем глобальный индекс потока
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // Загружаем данные из глобальной памяти в shared memory либо записываем 0 при выходе за границы
    sdata[tid] = (idx < n) ? in[idx] : 0.0f;
    // Синхронизируем все потоки блока после загрузки данных
    __syncthreads();

    // Выполняем параллельную редукцию внутри блока
    for (int s = blockDim.x / 2; s > 0; s >>= 1)
    {
        // Проверяем, участвует ли поток в текущем шаге редукции
        if (tid < s)
            // Складываем пару элементов в shared memory
            sdata[tid] += sdata[tid + s];
        // Синхронизируем потоки перед следующим шагом
        __syncthreads();
    }

    // Проверяем, является ли поток нулевым в блоке
    if (tid == 0)
        // Атомарно добавляем частичную сумму блока в глобальную сумму
        atomicAdd(out, sdata[0]);
}

// =====================================
// Раздел: Локальная пузырьковая сортировка в регистрах (local memory)
// =====================================

// Объявляем CUDA-ядро для сортировки небольших подмассивов методом пузырька
__global__ void local_bubble_kernel(float* data, int n)
{
    // Объявляем локальный массив для хранения подмассива из 32 элементов
    float local[32];

    // Получаем индекс текущего блока
    int block = blockIdx.x;
    // Получаем локальный индекс потока
    int tid = threadIdx.x;
    // Вычисляем начальный индекс подмассива в глобальном массиве
    int start = block * 32;

    // Проверяем, что индекс не выходит за границы массива
    if (start + tid < n)
        // Загружаем элемент из глобальной памяти в локальный массив
        local[tid] = data[start + tid];
    else
        // Заполняем фиктивным большим значением элементы за границей массива
        local[tid] = 1e30f;

    // Синхронизируем все потоки блока после загрузки данных
    __syncthreads();

    // Выполняем пузырьковую сортировку локального массива
    for (int i = 0; i < 32; ++i)
    {
        // Проверяем, что поток не выходит за пределы сравниваемой пары
        if (tid < 31 && local[tid] > local[tid + 1])
        {
            // Сохраняем временно значение текущего элемента
            float t = local[tid];
            // Перемещаем меньший элемент влево
            local[tid] = local[tid + 1];
            // Записываем сохраненное значение вправо
            local[tid + 1] = t;
        }
        // Синхронизируем потоки после каждой итерации обменов
        __syncthreads();
    }

    // Проверяем, что индекс не выходит за пределы массива
    if (start + tid < n)
        // Записываем отсортированное значение обратно в глобальную память
        data[start + tid] = local[tid];
}

// =====================================
// Раздел: Слияние блоков с использованием shared memory
// =====================================

// Объявляем CUDA-ядро для слияния двух отсортированных подмассивов
__global__ void merge_kernel(float* data, float* temp, int width, int n)
{
    // Объявляем разделяемый массив для хранения двух подмассивов
    __shared__ float s[512];

    // Получаем локальный индекс потока
    int tid = threadIdx.x;
    // Вычисляем начальный индекс обрабатываемого блока
    int start = blockIdx.x * width * 2;

    // Вычисляем начало первого подмассива
    int a = start;
    // Вычисляем начало второго подмассива
    int b = start + width;

    // Вычисляем конец первого подмассива с учётом границы массива
    int a_end = min(a + width, n);
    // Вычисляем конец второго подмассива с учётом границы массива
    int b_end = min(b + width, n);

    // Проверяем, что индекс не выходит за пределы массива
    if (start + tid < n)
        // Загружаем элемент первого подмассива в shared memory
        s[tid] = data[start + tid];
    else
        // Заполняем фиктивным большим значением элементы за границей
        s[tid] = 1e30f;

    // Проверяем, что индекс второго подмассива не выходит за пределы массива
    if (start + width + tid < n)
        // Загружаем элемент второго подмассива в shared memory
        s[width + tid] = data[start + width + tid];
    else
        // Заполняем фиктивным большим значением элементы за границей
        s[width + tid] = 1e30f;

    // Синхронизируем потоки после загрузки данных в shared memory
    __syncthreads();

    // Инициализируем индекс первого подмассива
    int i = 0;
    // Инициализируем индекс второго подмассива
    int j = width;

    // Запускаем цикл слияния элементов двух подмассивов
    for (int k = tid; k < (a_end - a) + (b_end - b); k += blockDim.x)
    {
        // Объявляем временную переменную для выбора минимального элемента
        float v;
        // Выбираем минимальный элемент из двух текущих
        if (s[i] < s[j]) v = s[i++]; else v = s[j++];
        // Записываем выбранный элемент во временный глобальный массив
        temp[start + k] = v;
    }
}

// =====================================
// Раздел: Хост-функции-обёртки для запуска CUDA-ядер
// =====================================

// Реализуем функцию редукции с использованием только глобальной памяти
void gpu_reduce_global(const float* d_in, int n, float& result, float& time_ms)
{
    // Объявляем указатель на память под результат на GPU
    float* d_out;
    // Выделяем память на GPU под один элемент типа float
    CUDA_CHECK(cudaMalloc(&d_out, sizeof(float)));
    // Обнуляем выделенную память на GPU
    CUDA_CHECK(cudaMemset(d_out, 0, sizeof(float)));

    // Объявляем события CUDA для измерения времени
    cudaEvent_t start, stop;
    // Создаём событие начала измерения
    cudaEventCreate(&start);
    // Создаём событие окончания измерения
    cudaEventCreate(&stop);

    // Регистрируем событие начала измерения времени
    cudaEventRecord(start);
    // Запускаем ядро редукции с использованием глобальной памяти
    reduce_global_kernel<<<(n + 255) / 256, 256>>>(d_in, d_out, n);
    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);
    // Ожидаем завершения всех операций
    cudaEventSynchronize(stop);

    // Вычисляем прошедшее время выполнения
    cudaEventElapsedTime(&time_ms, start, stop);

    // Копируем результат редукции из памяти GPU в память CPU
    CUDA_CHECK(cudaMemcpy(&result, d_out, sizeof(float), cudaMemcpyDeviceToHost));

    // Освобождаем память на GPU
    cudaFree(d_out);
    // Удаляем событие начала измерения
    cudaEventDestroy(start);
    // Удаляем событие окончания измерения
    cudaEventDestroy(stop);
}

// Реализуем функцию редукции с использованием разделяемой памяти
void gpu_reduce_shared(const float* d_in, int n, float& result, float& time_ms)
{
    // Объявляем указатель на память под результат на GPU
    float* d_out;
    // Выделяем память на GPU под один элемент типа float
    CUDA_CHECK(cudaMalloc(&d_out, sizeof(float)));
    // Обнуляем выделенную память на GPU
    CUDA_CHECK(cudaMemset(d_out, 0, sizeof(float)));

    // Объявляем события CUDA для измерения времени
    cudaEvent_t start, stop;
    // Создаём событие начала измерения
    cudaEventCreate(&start);
    // Создаём событие окончания измерения
    cudaEventCreate(&stop);

    // Регистрируем событие начала измерения времени
    cudaEventRecord(start);
    // Запускаем ядро редукции с использованием shared memory
    reduce_shared_kernel<<<(n + 255) / 256, 256>>>(d_in, d_out, n);
    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);
    // Ожидаем завершения всех операций
    cudaEventSynchronize(stop);

    // Вычисляем прошедшее время выполнения
    cudaEventElapsedTime(&time_ms, start, stop);

    // Копируем результат редукции из памяти GPU в память CPU
    CUDA_CHECK(cudaMemcpy(&result, d_out, sizeof(float), cudaMemcpyDeviceToHost));

    // Освобождаем память на GPU
    cudaFree(d_out);
    // Удаляем событие начала измерения
    cudaEventDestroy(start);
    // Удаляем событие окончания измерения
    cudaEventDestroy(stop);
}

// Реализуем функцию сортировки с использованием локальной памяти и слияния через shared memory
void gpu_sort_with_local_and_shared(float* d_data, int n, float& time_local_ms, float& time_merge_ms)
{
    // Объявляем указатель на временный массив в памяти GPU
    float* d_temp;
    // Выделяем память на GPU под временный массив
    CUDA_CHECK(cudaMalloc(&d_temp, n * sizeof(float)));

    // Объявляем события CUDA для измерения времени
    cudaEvent_t start, stop;
    // Создаём событие начала измерения
    cudaEventCreate(&start);
    // Создаём событие окончания измерения
    cudaEventCreate(&stop);

    // Регистрируем событие начала измерения времени
    cudaEventRecord(start);
    // Запускаем ядро локальной пузырьковой сортировки
    local_bubble_kernel<<<(n + 31) / 32, 32>>>(d_data, n);
    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);
    // Ожидаем завершения всех операций
    cudaEventSynchronize(stop);
    // Вычисляем время выполнения локальной сортировки
    cudaEventElapsedTime(&time_local_ms, start, stop);

    // Инициализируем текущую ширину сливаемых блоков
    int width = 32;
    // Обнуляем суммарное время слияния
    time_merge_ms = 0.0f;

    // Делаем только несколько стадий слияния, пока размер блоков помещается в shared memory
    while (width <= 256 && width < n)
    {
        // Вычисляем количество блоков для текущей стадии слияния
        int blocks = (n + 2 * width - 1) / (2 * width);

        // Регистрируем событие начала измерения времени
        cudaEventRecord(start);
        // Запускаем ядро слияния блоков
        merge_kernel<<<blocks, 256>>>(d_data, d_temp, width, n);
        // Регистрируем событие окончания измерения времени
        cudaEventRecord(stop);
        // Ожидаем завершения всех операций
        cudaEventSynchronize(stop);

        // Объявляем временную переменную для хранения времени текущей стадии
        float t;
        // Вычисляем время выполнения текущей стадии слияния
        cudaEventElapsedTime(&t, start, stop);
        // Добавляем время текущей стадии к суммарному времени слияния
        time_merge_ms += t;

        // Меняем местами указатели на основной и временный массивы
        std::swap(d_data, d_temp);
        // Увеличиваем ширину сливаемых блоков в два раза
        width *= 2;
    }

    // Освобождаем временный массив в памяти GPU
    cudaFree(d_temp);
    // Удаляем событие начала измерения
    cudaEventDestroy(start);
    // Удаляем событие окончания измерения
    cudaEventDestroy(stop);
}
