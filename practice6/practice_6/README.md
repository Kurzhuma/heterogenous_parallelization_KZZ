# Практическая работа №6
**Тема:** Программирование на OpenCL для CPU и GPU

---

## Цель работы

- Изучение основ программирования на OpenCL.
- Разработка кросс-платформенного приложения для выполнения параллельных вычислений на CPU и GPU.
- Сравнение производительности вычислений на различных типах устройств.

---

## Описание работы

В рамках данной практической работы было реализовано приложение с использованием OpenCL, выполняющее:

1. Поэлементное сложение двух векторов.
2. Умножение двух матриц.

Программа может выполняться как на CPU, так и на GPU, что позволяет сравнить производительность различных вычислительных устройств в рамках одной и той же программной модели.

---

## Структура проекта

- `main.cpp` — точка входа в программу, запуск тестов для CPU и GPU.
- `opencl_utils.cpp / opencl_utils.h` — вспомогательные функции для инициализации OpenCL, загрузки ядер и выполнения вычислений.
- `kernel_vector_add.cl` — OpenCL-ядро для сложения векторов.
- `kernel_matmul.cl` — OpenCL-ядро для умножения матриц.
- `CMakeLists.txt` — файл сборки проекта.

---

## Реализованные задачи

### Задача 1: Поэлементное сложение векторов

- Реализовано OpenCL-ядро `vector_add`.
- Выполнена инициализация платформы и устройства (CPU или GPU).
- Созданы контекст и командная очередь.
- Подготовлены данные и выполнено ядро.
- Результаты считаны обратно в память хоста.
- Измерено время выполнения на CPU и GPU.

### Задача 2: Умножение матриц

- Реализовано OpenCL-ядро `matmul`.
- Матрицы передаются в память устройства.
- Размеры матриц передаются в качестве аргументов ядра.
- Запуск производится в двумерной сетке рабочих элементов.
- Результаты сравниваются по времени выполнения на CPU и GPU.

---

## Результаты выполнения

Консольный вывод программы:

OpenCL CPU Vector Add

Time: 0.0493 ms

OpenCL GPU Vector Add

Time: 0.02 ms

OpenCL CPU MatMul

Time: 0.0131 ms

OpenCL GPU MatMul

Time: 0.0089 ms


---

## Анализ результатов

1. Во всех измерениях GPU демонстрирует более высокую производительность по сравнению с CPU.
2. Для операции сложения векторов ускорение на GPU составляет примерно 2–2.5 раза.
3. Для операции умножения матриц ускорение также заметно, несмотря на относительно небольшой размер матриц.
4. Даже с учётом накладных расходов на запуск OpenCL-ядер, GPU показывает преимущество за счёт массового параллелизма вычислений.
5. Разница особенно проявилась бы сильнее при увеличении размеров обрабатываемых данных.

---

## Выводы

- OpenCL позволяет писать единый код, который может выполняться как на CPU, так и на GPU.
- GPU обеспечивает более высокую производительность для параллельных вычислений за счёт большого количества вычислительных ядер.
- Для небольших размеров данных выигрыш ограничен накладными расходами, однако при масштабировании задач преимущество GPU становится существенным.
- OpenCL является удобным инструментом для создания кросс-платформенных высокопроизводительных вычислительных приложений.

---

## Ответы на контрольные вопросы

### 1. Какие основные типы памяти используются в OpenCL?

В OpenCL используются следующие основные типы памяти:
- Глобальная память — доступна всем рабочим элементам, но имеет высокую задержку.
- Локальная память — общая для рабочей группы, используется для ускорения обмена данными между потоками.
- Приватная память — доступна только одному рабочему элементу.
- Константная память — предназначена для хранения неизменяемых данных.

---

### 2. Как настроить глобальную и локальную рабочую группу?

Глобальный размер задаёт общее количество рабочих элементов, а локальный — размер одной рабочей группы. Эти параметры передаются в функцию `clEnqueueNDRangeKernel` при запуске ядра.

---

### 3. Чем отличается OpenCL от CUDA?

CUDA является проприетарной технологией NVIDIA и работает только на их GPU. OpenCL — это открытый стандарт, поддерживающий устройства различных производителей, включая CPU, GPU и другие ускорители.

---

### 4. Какие преимущества дает использование OpenCL?

- Кросс-платформенность.
- Возможность использовать одно приложение для CPU и GPU.
- Масштабируемость под разные типы устройств.
- Высокая производительность для параллельных вычислений.

---

