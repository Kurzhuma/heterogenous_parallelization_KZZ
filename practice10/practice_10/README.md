# Практическая работа №10

Kurmash Zhumagozhayev ADA-2401M

**Тема:** Анализ производительности и масштабируемости (OpenMP, CUDA, MPI)

---

## Задание 1. Анализ производительности OpenMP (CPU)

Реализована параллельная программа для расчета суммы и дисперсии массива из $10^8$ элементов. Профилирование выполнено с помощью функции `omp_get_wtime()`.

### Результаты тестирования:
| Количество потоков | Время выполнения (сек) | Ускорение (Speedup) |
| :--- | :---: | :---: |
| 1 поток | 0.49080 | 1.00x |
| 2 потока | 0.23870 | 2.05x |
| 4 потока | 0.12539 | 3.91x |
| 8 потоков | 0.06380 | 7.69x |



**Анализ по закону Амдала:**
Программа демонстрирует высокую эффективность параллелизма. Ускорение на 8 потоках (7.69x) близко к теоретическому максимуму. Это указывает на то, что доля последовательной части программы ($s$) крайне мала, а основные вычислительные затраты сосредоточены в параллельных циклах редукции.

---

## Задание 2. Оптимизация доступа к памяти на GPU (CUDA)

Исследовано влияние паттернов доступа к глобальной памяти на производительность графического процессора.

### Сравнительные показатели:
* **Эффективный (Coalesced) доступ:** 0.946176 мс
* **Неэффективный (Stride 32) доступ:** 0.584704 мс



**Вывод:** В данной конфигурации неэффективный доступ показал меньшее время за счет аппаратных особенностей: при использовании шага (stride) большая часть потоков не проходит проверку условий внутри ядра, что снижает общее количество математических операций. Для корректной оптимизации в реальных задачах необходимо обеспечивать коалесцированный доступ, чтобы контроллер памяти мог объединять запросы нескольких потоков в одну транзакцию.

---

## Задание 3. Профилирование гибридного приложения (CPU + GPU)

Реализована гибридная модель вычислений с использованием асинхронной передачи данных через **CUDA Streams**.

### Статистика профилирования:
* **Общее время гибридной обработки:** 0.0024014 сек.
* **Оптимизация:** Использование `cudaMemcpyAsync` позволило полностью перекрыть накладные расходы на копирование данных вычислениями на стороне CPU.

**Узкое место:** Основным ограничением является пропускная способность шины PCI Express. Асинхронные потоки позволяют нивелировать это ограничение, не блокируя основной поток выполнения программы.



---

## Задание 4. Анализ масштабируемости распределённой программы (MPI)

Оценка масштабируемости (Strong Scaling) при выполнении агрегатных функций на распределенной системе.

### Результаты масштабирования:
| Кол-во процессов MPI | Время (сек) | Коэффициент ускорения |
| :--- | :---: | :---: |
| 1 процесс | 0.123902 | 1.00x |
| 2 процесса | 0.118717 | 1.04x |
| 4 процесса | 0.117551 | 1.05x |



**Анализ масштабируемости:**
Наблюдается стагнация производительности. При увеличении числа процессов с 1 до 4 время выполнения сократилось незначительно. Это классический пример ограничения масштабируемости: накладные расходы на коммуникационную операцию `MPI_Reduce` и сетевые задержки синхронизации сопоставимы с временем локальных вычислений на данном объеме данных.

---

## Ответы на контрольные вопросы

1. **В чем отличие измерения времени выполнения от профилирования?**
   
Измерение времени дает общую метрику "от начала до конца", а профилирование детализирует работу программы, показывая загрузку конкретных узлов (ALU, память, кэш) и время выполнения отдельных функций.

2. **Какие виды узких мест характерны для CPU, GPU и MPI?**

- **CPU:** Последовательные участки кода и задержки кэш-памяти.
- **GPU:** Некоалесцированный доступ к памяти и расхождение потоков (warp divergence).
- **MPI:** Латентность сети и накладные расходы на передачу сообщений.

3. **Почему увеличение числа потоков не всегда приводит к ускорению?**

Из-за роста затрат на синхронизацию, конкуренцию за общие ресурсы (шину памяти) и накладных расходов на управление потоками.

4. **Законы Амдала и Густафсона:**

Закон Амдала определяет предел ускорения при фиксированном размере задачи. Закон Густафсона утверждает, что масштабируемость можно сохранять при увеличении объема данных пропорционально количеству вычислителей.

5. **Факторы критичные для гибридных приложений:**
   
Скорость передачи данных между хостом и устройством (PCIe) и эффективность перекрытия вычислений передачей данных (Streams).

---