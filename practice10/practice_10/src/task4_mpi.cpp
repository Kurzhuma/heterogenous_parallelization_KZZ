/**
 * ЗАДАНИЕ 4. АНАЛИЗ МАСШТАБИРУЕМОСТИ РАСПРЕДЕЛЁННОЙ ПРОГРАММЫ (MPI)
 */

// Подключение библиотеки передачи сообщений MPI
#include <mpi.h>
// Подключение стандартных библиотек C++
#include <iostream>
// Подключение динамических массивов
#include <vector>
// Подключение заголовка для настройки кодировки Windows
#include <windows.h>

int main(int argc, char** argv) {
    // Инициализация кодовой страницы UTF-8 на уровне операционной системы
    SetConsoleOutputCP(65001);

    // Инициализация коммуникационной среды MPI
    MPI_Init(&argc, &argv);

    // Переменные для хранения ранга процесса и общего их количества
    int rank, size;
    // Определение идентификатора текущего процесса в коммуникаторе
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    // Определение суммарного количества запущенных процессов
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // Увеличим локальный массив до 50 миллионов на процесс
    const int N_per_proc = 50000000;
    // Локальный вектор данных для проведения агрегации
    std::vector<double> local_data(N_per_proc, 1.0);

    // Замер времени начала выполнения распределенного алгоритма
    double start_time = MPI_Wtime();

    // Переменные для накопления локального и глобального результатов
    double local_sum = 0, global_sum = 0;

    // Итерационный расчет локальной суммы элементов процесса
    for(double val : local_data) {
        local_sum += val;
    }

    // Коллективная операция редукции: сбор локальных сумм со всех узлов в одну
    MPI_Reduce(&local_sum, &global_sum, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);

    // Фиксация времени окончания вычислений на каждом узле
    double end_time = MPI_Wtime();

    // Вывод результатов анализа масштабируемости процессом с рангом 0
    if (rank == 0) {
        // Отображение количества процессов и затраченного времени
        std::cout << "Количество процессов MPI: " << size
                  << " | Время выполнения агрегации: " << end_time - start_time << " сек." << std::endl;
        // Примечание: для оценки Strong Scaling следует делить общее N на число процессов
    }

    // Завершение работы с интерфейсом MPI и освобождение ресурсов
    MPI_Finalize();

    return 0;
}