# Практическая работа №8

Kurmash Zhumagozhayev ADA-2401M

**Тема:** Разработка гибридного приложения для CPU и GPU

---

## Цель работы

- Изучение принципов распределения вычислительной нагрузки между центральным (CPU) и графическим (GPU) процессорами.
- Оптимизация взаимодействия OpenMP и CUDA в рамках одного приложения.
- Анализ производительности и выявление «узких мест» при гибридных вычислениях.

---

## Описание работы

В данной работе реализовано приложение, выполняющее поэлементную обработку массива (умножение каждого элемента на 2.0). Исследованы три сценария работы:

1. **CPU Only:** Параллельная обработка на всех ядрах процессора с использованием OpenMP.
2. **GPU Only:** Полный цикл обработки на видеокарте (выделение памяти, копирование HtoD, ядро, копирование DtoH).
3. **Hybrid:** Одновременная работа — первая половина массива обрабатывается процессором, вторая в это же время обрабатывается видеокартой.

---

## Исходный код

Проект реализован на языке C++/CUDA. Основные компоненты:
- **Ядро CUDA:** `processGPUKernel` для параллельной обработки на GPU.
- **Функция OpenMP:** `processCPU` с использованием директивы `#pragma omp parallel for`.
- **Механизм синхронизации:** `cudaDeviceSynchronize()` для обеспечения корректного завершения гибридной фазы.

---

## Результаты тестирования (N = 10,000,000)

| Режим работы | Время выполнения (ms) | Ускорение (отн. Гибрида) |
| :--- | :---: | :---: |
| **CPU Only (OpenMP)** | 7.9277 | 1.80x (быстрее) |
| **GPU Only (CUDA)** | 132.0836 | 0.11x (медленнее) |
| **Hybrid (CPU + GPU)** | 14.2524 | 1.00x |

---

## Анализ производительности (Задание 4)

1. **Доминирование CPU:** В данной задаче CPU оказался самым быстрым. Это связано с тем, что работа с кэш-памятью процессора происходит быстрее, чем подготовка и пересылка 40 Мб данных в видеопамять через шину PCI Express.
2. **Накладные расходы GPU:** Время GPU (132 мс) почти на 95% состоит из времени копирования данных. Сами вычисления на RTX занимают микросекунды, но «бутылочное горлышко» шины данных замедляет процесс.
3. **Гибридный режим:** Время гибридного режима (14.25 мс) выше времени CPU. Это объясняется тем, что программа вынуждена ждать завершения GPU-части для своей половины данных. Однако гибридный режим в **9.27 раза быстрее** чистого GPU, так как CPU взял на себя половину нагрузки, не требующей пересылок.

---

## Выводы

1. **Эффективность гибридного подхода:** Гибридные вычисления наиболее эффективны в задачах с высокой вычислительной сложностью, где время счета значительно превышает время пересылки данных.
2. **Факторы влияния:** На производительность влияют пропускная способность шины PCIe, балансировка нагрузки (Load Balancing) и накладные расходы на запуск потоков.
3. **Оптимизация:** Для минимизации задержек рекомендуется использовать асинхронные вызовы (`cudaMemcpyAsync`) и потоки CUDA (Streams), чтобы перекрывать время передачи данных временем вычислений на CPU.

---

## Ответы на контрольные вопросы

### 1. Какие преимущества предоставляют гибридные вычисления?
Возможность задействовать 100% аппаратных ресурсов компьютера. Пока GPU занят тяжелыми вычислениями, CPU может обрабатывать логику, ввод-вывод или свою часть массива, сокращая общее время простоя.

### 2. Как минимизировать накладные расходы при передаче данных между CPU и GPU?
- Использовать «закрепленную» (Pinned) память (`cudaHostAlloc`).
- Группировать мелкие пересылки в одну большую.
- Использовать асинхронное копирование одновременно с вычислениями.

### 3. Какие задачи лучше выполнять на CPU, а какие на GPU?
- **CPU:** Задачи с ветвлениями, рекурсией, сложной логикой и малым объемом данных.
- **GPU:** Массово-параллельные задачи с огромным количеством однотипных математических операций над большими массивами.

### 4. Как можно улучшить производительность гибридного приложения?
Необходимо динамически подбирать пропорцию разделения данных. Если GPU с учетом пересылок работает медленнее, стоит отдавать ему меньшую часть массива (например, 20/80 вместо 50/50), чтобы оба устройства заканчивали работу одновременно.