# Практическая работа №7

Kurmash Zhumagozhayev ADA-2401M

**Тема:** Редукция и сканирование на GPU с использованием CUDA

---

## Цель работы

- Изучение и реализация параллельных алгоритмов редукции и сканирования (префиксной суммы) на GPU.
- Исследование производительности алгоритмов при различных объемах данных.
- Оптимизация кода с использованием разделяемой (shared) памяти CUDA.

---

## Описание работы

В рамках данной практической работы на языке C++ с использованием технологии NVIDIA CUDA были реализованы:

1. **Параллельная редукция** — вычисление суммы элементов массива.
2. **Параллельное сканирование** — вычисление эксклюзивной префиксной суммы (алгоритм Blelloch).

Программа выполняет вычисления как на CPU (последовательно), так и на GPU (параллельно), что позволяет провести сравнительный анализ производительности и рассчитать ускорение (Speedup).

---

## Структура проекта

- `main.cu` — основной файл с исходным кодом, содержащий ядра CUDA, CPU-реализации и бенчмарки.
- `utils.h` — вспомогательные макросы для обработки ошибок CUDA (CHECK_CUDA).
- `CMakeLists.txt` — файл конфигурации сборки проекта для CLion.
- `README.md` — файл Readme.

---

## Реализованные задачи

### Задача 1: Реализация редукции (сумма элементов)

- Реализовано ядро CUDA `reduceKernel`.
- Использована **разделяемая память (shared memory)** для суммирования элементов внутри блока потоков.
- Для объединения результатов блоков применена атомарная операция `atomicAdd`.
- Выполнены замеры времени на массивах от 1024 до 10 000 000 элементов.

### Задача 2: Реализация префиксной суммы (сканирование)

- Реализован алгоритм **Blelloch Scan**, состоящий из фаз Up-sweep (восходящий проход) и Down-sweep (нисходящий проход).
- Использована разделяемая память для минимизации обращений к глобальной памяти GPU.
- Реализована поддержка многоблочного сканирования для обработки больших массивов (10^7 элементов).
- Проведена верификация результатов в сравнении с последовательным CPU-алгоритмом.

---

## Результаты выполнения

Консольный вывод программы (GeForce RTX):

=== ТЕСТ: 1024 ЭЛЕМЕНТОВ ===

[REDUCE] CPU:   0.0023 ms | GPU:   0.4513 ms | Speedup: 0.01x

[SCAN]   CPU:   0.0020 ms | GPU:   0.1924 ms | Speedup: 0.01x

=== ТЕСТ: 1000000 ЭЛЕМЕНТОВ ===

[REDUCE] CPU:   2.0692 ms | GPU:   0.0887 ms | Speedup: 23.33x

[SCAN]   CPU:   2.1923 ms | GPU:   0.2828 ms | Speedup: 7.75x

=== ТЕСТ: 10000000 ЭЛЕМЕНТОВ ===

[REDUCE] CPU:  23.5911 ms | GPU:   0.6506 ms | Speedup: 36.26x

[SCAN]   CPU:  33.1847 ms | GPU:   2.3295 ms | Speedup: 14.25x

---

## Анализ результатов

1. **Малые объемы данных (1024):** GPU показывает крайне низкую производительность (Speedup 0.01x). Это обусловлено накладными расходами на инициализацию CUDA-контекста, копирование данных и запуск ядер.
2. **Масштабируемость:** С ростом массива до 1 000 000 элементов преимущество GPU становится очевидным (ускорение в 23 раза для редукции).
3. **Максимальный объем (10 000 000):** На больших данных GPU демонстрирует пиковую эффективность. Редукция выполняется в **36 раз быстрее**, а сканирование в **14 раз быстрее**, чем на CPU.
4. **Алгоритмическая сложность:** Сканирование является более трудоемкой операцией по сравнению с редукцией, что отражается на времени выполнения (2.3295 ms против 0.6506 ms на максимальном массиве).
5. **Оптимизация:** Использование разделяемой памяти позволило эффективно реализовать дерево вычислений внутри блоков.

---

## Выводы

- Технология CUDA значительно превосходит CPU в задачах массового параллелизма, таких как редукция и сканирование больших массивов.
- Эффективность GPU напрямую зависит от объема обрабатываемых данных: чем больше массив, тем выше Speedup.
- Разделяемая память является ключевым инструментом оптимизации в CUDA, позволяя сократить количество обращений к медленной глобальной памяти.
- Для успешной реализации сканирования на GPU необходимо учитывать иерархию блоков и обеспечивать синхронизацию между ними.

---

## Ответы на контрольные вопросы

### 1. В чем разница между редукцией и сканированием?
Редукция сводит массив данных к одному итоговому значению (например, сумма). Сканирование (префиксная сумма) формирует новый массив, где каждый элемент является суммой всех предыдущих элементов входного массива.

### 2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?
- **Глобальная память:** для хранения исходных данных.
- **Разделяемая (Shared) память:** для быстрой обработки промежуточных данных внутри блока потоков и построения вычислительного дерева.

### 3. Как можно оптимизировать префиксную сумму на GPU?
Использованием эффективных алгоритмов (Blelloch или Hillis-Steele), минимизацией конфликтов банков памяти (bank conflicts) в разделяемой памяти и использованием многоуровневого подхода для обработки массивов, превышающих размер одного блока.

### 4. Приведите пример задачи, где применяется сканирование.
Сканирование применяется в алгоритмах сжатия данных, при реализации быстрой сортировки (Radix Sort), в физических симуляциях и при построении структур данных для трассировки лучей.