# Assignment 2 Kurmash Zhumagozhayev ADA-2401M


---

## Содержание
1. Описание задания
2. Описание реализованных программ (Выполнен на NVIDIA GeForce RTX 2080 Ti)
    - CPU (OpenMP)
    - GPU (CUDA)
3. Результаты выполнения
4. Выводы по результатам
5. Ответы на контрольные вопросы

---

## 1. Описание задания
 
*Assignment 2** посвящена изучению принципов
**гетерогенной параллелизации**, то есть распределения вычислений между
устройствами с различной архитектурой (CPU и GPU).

В рамках задания были выполнены следующие этапы:

1. Изучение теоретических основ гетерогенных вычислений.
2. Реализация поиска минимума и максимума массива:
    - последовательная версия;
    - параллельная версия с использованием OpenMP.
3. Реализация сортировки выбором:
    - последовательная версия;
    - параллельная версия с использованием OpenMP.
4. Реализация сортировки слиянием на GPU с использованием CUDA.
5. Анализ полученных результатов и формулирование выводов.

---

## 2. Описание реализованных программ

### 2.1 CPU-реализация (OpenMP)

CPU-часть программы реализована на языке C++ с использованием технологии **OpenMP**.

Функциональность CPU-части:
- генерация массива случайных чисел;
- поиск минимального и максимального значения:
    - последовательный алгоритм;
    - параллельный алгоритм с использованием директивы `reduction`;
- сортировка выбором:
    - последовательная версия;
    - параллельная версия с использованием OpenMP.

Для измерения времени выполнения используется библиотека `std::chrono`.

Следует отметить, что сортировка выбором содержит зависимости между итерациями,
а также критические секции, что ограничивает эффективность параллелизации.

---

### 2.2 GPU-реализация (CUDA)

GPU-часть реализована с использованием **CUDA** и демонстрирует
гетерогенный подход к вычислениям.

Основные особенности реализации:
- массив разбивается на подмассивы фиксированного размера;
- каждый подмассив сортируется отдельным CUDA-блоком;
- для корректности используется один поток на блок;
- итоговое слияние подмассивов выполняется на CPU;
- измерение времени производится с помощью `std::chrono`;
- измеряется суммарное время выполнения 100 запусков
  (CUDA-ядро + операции копирования памяти).

Данная реализация ориентирована на демонстрацию принципов
гетерогенных вычислений, а не на достижение максимальной производительности.

---

## 3. Результаты выполнения

### CPU (OpenMP)

OpenMP threads: 32

Min/Max sequential time: 0.054821 ms
Min/Max OpenMP time: 11.3951 ms

Selection sort sequential (1000): 2.51297 ms
Selection sort OpenMP (1000): 952.471 ms

Selection sort sequential (10000): 195.53 ms
Selection sort OpenMP (10000): 13932.8 ms

### GPU (CUDA)

Array size: 10000
GPU time (100 runs, kernel + memcpy): 0.024 ms

Array size: 100000
GPU time (100 runs, kernel + memcpy): 0.008 ms

## 4. Выводы по результатам

1. Параллелизация не всегда приводит к ускорению выполнения программы.
   Для задач с высокой степенью синхронизации и зависимостей между итерациями
   (например, сортировка выбором) использование OpenMP может приводить
   к значительному замедлению.

2. OpenMP наиболее эффективен для простых независимых операций,
   таких как поиск минимума и максимума массива.

3. GPU-реализация демонстрирует очень малое время выполнения,
   что связано с простотой CUDA-ядра и использованием одного потока на блок.

4. Гетерогенный подход позволяет эффективно распределять вычисления:
    - GPU выполняет массовые однотипные операции;
    - CPU выполняет последовательные части алгоритма и управление процессом.

5. Полученные результаты подтверждают, что выбор архитектуры
   должен осуществляться с учётом характера решаемой задачи,
   а не только на основе возможности параллелизации.

---

## 5. Ответы на контрольные вопросы

### 1. Что такое гетерогенная параллелизация?
Гетерогенная параллелизация — это подход к вычислениям, при котором
используются устройства с различной архитектурой (CPU, GPU и др.)
для более эффективного выполнения задач.

### 2. В чём основные различия архитектур CPU и GPU?
CPU содержит небольшое количество мощных ядер и оптимизирован
для последовательных и логически сложных задач.
GPU содержит большое количество простых ядер и предназначен
для массовых параллельных вычислений.

### 3. Какие задачи лучше подходят для GPU, а какие для CPU?
GPU эффективен для задач с большим количеством однотипных операций
(работа с массивами, матрицами, изображениями).
CPU лучше подходит для задач с ветвлениями, сложной логикой
и зависимостями между данными.

### 4. Почему не все алгоритмы эффективно распараллеливаются с помощью OpenMP?
Причиной являются зависимости между итерациями, критические секции
и накладные расходы на синхронизацию потоков.

### 5. В чём заключается идея алгоритма сортировки слиянием?
Алгоритм сортировки слиянием основан на разбиении массива на части,
их сортировке и последующем слиянии в один отсортированный массив.

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?
Основные сложности связаны с синхронизацией потоков,
эффективным управлением памятью и минимизацией копирования данных
между CPU и GPU.

### 7. Как размер блока и сетки влияет на производительность GPU?
Размер блока и сетки влияет на степень загрузки GPU,
использование ресурсов и общую эффективность выполнения CUDA-ядра.

### 8. Почему гетерогенный подход может быть эффективнее,
чем использование только CPU или только GPU?
Гетерогенный подход позволяет использовать сильные стороны
каждого устройства и минимизировать их ограничения.

---
