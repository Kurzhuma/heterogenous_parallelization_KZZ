//Assignment 2

/* Подключаем стандартный поток вывода для печати результатов */
#include <iostream>

/* Подключаем контейнер vector для хранения массива на CPU */
#include <vector>

/* Подключаем библиотеку времени */
#include <chrono>

/* Подключаем генератор случайных чисел для создания входных данных */
#include <random>

/* Подключаем CUDA Runtime API для работы с GPU */
#include <cuda_runtime.h>

/* Используем стандартное пространство имён */
using namespace std;

/* CUDA-ядро, в котором один поток обрабатывает один подмассив */
__global__ void block_sort(int* data, int n, int blockSize)
{
    /* Проверяем, что выполняется только первый поток блока */
    if (threadIdx.x != 0)
        /* Завершаем выполнение ядра для остальных потоков */
        return;

    /* Вычисляем начальный индекс подмассива для текущего блока */
    int start = blockIdx.x * blockSize;

    /* Проверяем, не выходит ли подмассив за границы массива */
    if (start + blockSize > n)
        /* Завершаем выполнение ядра при выходе за границы */
        return;

    /* Запускаем внешний цикл пузырьковой сортировки */
    for (int i = 0; i < blockSize; ++i)
    {
        /* Запускаем внутренний цикл сравнения соседних элементов */
        for (int j = start; j < start + blockSize - 1; ++j)
        {
            /* Проверяем, требуется ли обмен элементов */
            if (data[j] > data[j + 1])
            {
                /* Сохраняем значение текущего элемента */
                int t = data[j];

                /* Перемещаем больший элемент вправо */
                data[j] = data[j + 1];

                /* Завершаем операцию обмена */
                data[j + 1] = t;
            }
        }
    }
}

/* CPU-функция выполняет поэтапное слияние отсортированных подмассивов */
void merge_blocks(vector<int>& a, int blockSize)
{
    /* Создаём временный массив для хранения результатов слияния */
    vector<int> tmp(a.size());

    /* Начинаем с ширины, равной размеру блока */
    for (int width = blockSize; width < (int)a.size(); width *= 2)
    {
        /* Проходим по массиву с шагом двойной ширины */
        for (int i = 0; i < (int)a.size(); i += 2 * width)
        {
            /* Левая граница первого подмассива */
            int l = i;

            /* Средняя граница между подмассивами */
            int m = min(i + width, (int)a.size());

            /* Правая граница второго подмассива */
            int r = min(i + 2 * width, (int)a.size());

            /* Индекс первого подмассива */
            int i1 = l;

            /* Индекс второго подмассива */
            int i2 = m;

            /* Индекс записи во временный массив */
            int k = l;

            /* Выполняем основное слияние двух отсортированных частей */
            while (i1 < m && i2 < r)
                /* Записываем меньший элемент во временный массив */
                tmp[k++] = (a[i1] < a[i2]) ? a[i1++] : a[i2++];

            /* Копируем оставшиеся элементы первого подмассива */
            while (i1 < m)
                /* Переносим элемент во временный массив */
                tmp[k++] = a[i1++];

            /* Копируем оставшиеся элементы второго подмассива */
            while (i2 < r)
                /* Переносим элемент во временный массив */
                tmp[k++] = a[i2++];
        }

        /* Переносим результаты слияния обратно в основной массив */
        a = tmp;
    }
}

/* Главная функция программы */
int main()
{
    /* Выводим заголовок GPU-части задания */
    cout << "Assignment 2 | GPU CUDA Merge Sort\n";

    /* Перебираем размеры массивов, указанные в задании */
    for (int n : {10000, 100000})
    {
        /* Выводим текущий размер массива */
        cout << "\nArray size: " << n << "\n";

        /* Создаём массив на стороне CPU */
        vector<int> host(n);

        /* Создаём генератор случайных чисел */
        mt19937 gen(random_device{}());

        /* Определяем диапазон значений */
        uniform_int_distribution<> dist(0, 100000);

        /* Заполняем массив случайными значениями */
        for (int i = 0; i < n; ++i)
            /* Присваиваем элементу случайное значение */
            host[i] = dist(gen);

        /* Объявляем указатель на память GPU */
        int* dev = nullptr;

        /* Выделяем память на GPU под массив */
        cudaMalloc(&dev, n * sizeof(int));

        /* Задаём размер подмассива, обрабатываемого одним блоком */
        int blockSize = 256;

        /* Вычисляем количество блоков */
        int blocks = n / blockSize;

        /* Запоминаем момент начала измерения времени GPU-пайплайна */
        auto t_start = std::chrono::high_resolution_clock::now();

        /* Повторяем GPU-пайплайн 100 раз для получения измеримого времени */
        for (int rep = 0; rep < 100; ++rep)
        {
            cudaMemcpy(dev,
                       host.data(),
                       n * sizeof(int),
                       cudaMemcpyHostToDevice);

            block_sort<<<blocks, 1>>>(dev, n, blockSize);

            cudaDeviceSynchronize();

            cudaMemcpy(host.data(),
                       dev,
                       n * sizeof(int),
                       cudaMemcpyDeviceToHost);
        }

        /* Запоминаем момент окончания измерения времени */
        auto t_end = std::chrono::high_resolution_clock::now();

        /* Вычисляем общее время выполнения всех запусков в микросекундах */
        auto total_us =
            std::chrono::duration_cast<std::chrono::microseconds>(t_end - t_start).count();

        /* Переводим время из микросекунд в миллисекунды */
        double total_ms = total_us / 1000.0;

        /* Вычисляем среднее время одного GPU-запуска */
        double avg_ms = total_ms / 100.0;

        /* Выводим время выполнения GPU-пайплайна */
        cout << "GPU time (100 runs, kernel + memcpy): " << total_ms << " ms\n";


        /* Выполняем финальное слияние подмассивов на CPU */
        merge_blocks(host, blockSize);

        /* Освобождаем память на GPU */
        cudaFree(dev);


    }

    /* Корректно завершаем программу */
    return 0;
}

