// Подключаем заголовочный файл CUDA Runtime API для работы с функциями CUDA
#include <cuda_runtime.h>

// Подключаем стандартную библиотеку для вывода сообщений в консоль
#include <iostream>

// Подключаем заголовочный файл с объявлениями функций тестирования структур данных
#include "structures.h"

// Определяем макрос для проверки корректности выполнения вызовов CUDA API
#define CUDA_CHECK(x) do { cudaError_t err = x; if (err != cudaSuccess) { \
    std::cerr << "CUDA error: " << cudaGetErrorString(err) << std::endl; exit(1); } } while(0)

// =====================================
// Реализация параллельного стека (LIFO)
// =====================================

// Объявляем структуру данных Stack для реализации стека в памяти GPU
struct Stack {
    // Указатель на массив данных, размещённый в глобальной памяти GPU
    int* data;

    // Переменная, хранящая индекс вершины стека
    int top;

    // Переменная, задающая максимальную ёмкость стека
    int capacity;

    // Определяем метод добавления элемента в стек, выполняемый на устройстве
    __device__ bool push(int value) {
        // Атомарно увеличиваем индекс вершины стека и получаем позицию для записи
        int pos = atomicAdd(&top, 1);

        // Проверяем, что полученная позиция не превышает ёмкость стека
        if (pos < capacity) {
            // Записываем значение в соответствующую ячейку массива
            data[pos] = value;

            // Сообщаем об успешном выполнении операции
            return true;
        }

        // В случае переполнения стека сообщаем о неуспехе операции
        return false;
    }

    // Определяем метод извлечения элемента из стека, выполняемый на устройстве
    __device__ bool pop(int* value) {
        // Атомарно уменьшаем индекс вершины стека и получаем позицию для чтения
        int pos = atomicSub(&top, 1);

        // Проверяем, что в стеке есть элементы
        if (pos >= 0) {
            // Считываем значение из соответствующей ячейки массива
            *value = data[pos];

            // Сообщаем об успешном выполнении операции
            return true;
        }

        // В случае, если стек пуст, сообщаем о неуспехе операции
        return false;
    }
};

// Объявляем CUDA-ядро для параллельного добавления элементов в стек
__global__ void stack_push_kernel(Stack* stack, int N)
{
    // Вычисляем глобальный индекс текущего потока
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // Проверяем, что индекс не выходит за пределы обрабатываемого диапазона
    if (idx < N)
        // Вызываем операцию добавления элемента в стек
        stack->push(idx);
}

// Объявляем CUDA-ядро для параллельного извлечения элементов из стека
__global__ void stack_pop_kernel(Stack* stack, int* out, int N)
{
    // Вычисляем глобальный индекс текущего потока
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // Проверяем, что индекс не выходит за пределы обрабатываемого диапазона
    if (idx < N)
        // Вызываем операцию извлечения элемента из стека и сохраняем результат в выходной массив
        stack->pop(&out[idx]);
}

// =====================================
// Реализация MPMC очереди (кольцевой буфер) с использованием shared memory
// =====================================

// Объявляем структуру данных Queue для реализации очереди в памяти GPU
struct Queue {
    // Указатель на массив данных, размещённый в глобальной памяти GPU
    int* data;

    // Индекс начала очереди
    int head;

    // Индекс конца очереди
    int tail;

    // Переменная, задающая максимальную ёмкость очереди
    int capacity;

    // Определяем метод добавления элемента в очередь, выполняемый на устройстве
    __device__ bool enqueue(int value) {
        // Атомарно увеличиваем индекс конца очереди
        int pos = atomicAdd(&tail, 1);

        // Вычисляем позицию в кольцевом буфере по модулю ёмкости
        int idx = pos % capacity;

        // Записываем значение в вычисленную позицию
        data[idx] = value;

        // Сообщаем об успешном выполнении операции
        return true;
    }

    // Определяем метод извлечения элемента из очереди, выполняемый на устройстве
    __device__ bool dequeue(int* value) {
        // Атомарно увеличиваем индекс начала очереди
        int pos = atomicAdd(&head, 1);

        // Проверяем, что в очереди есть элементы для чтения
        if (pos < tail) {
            // Вычисляем позицию в кольцевом буфере по модулю ёмкости
            int idx = pos % capacity;

            // Считываем значение из очереди
            *value = data[idx];

            // Сообщаем об успешном выполнении операции
            return true;
        }

        // В случае отсутствия элементов сообщаем о неуспехе операции
        return false;
    }
};

// Объявляем CUDA-ядро для параллельного добавления элементов в очередь с использованием shared memory
__global__ void queue_enqueue_kernel(Queue* queue, int N)
{
    // Объявляем разделяемый буфер для временного хранения данных внутри блока потоков
    __shared__ int buffer[256];

    // Получаем локальный индекс потока внутри блока
    int tid = threadIdx.x;

    // Вычисляем глобальный индекс текущего потока
    int idx = blockIdx.x * blockDim.x + tid;

    // Проверяем, что индекс не выходит за пределы обрабатываемого диапазона
    if (idx < N)
        // Сохраняем значение во временный разделяемый буфер
        buffer[tid] = idx;

    // Синхронизируем все потоки блока перед дальнейшими действиями
    __syncthreads();

    // Проверяем, что индекс не выходит за пределы обрабатываемого диапазона
    if (idx < N)
        // Добавляем элемент в очередь, используя данные из разделяемой памяти
        queue->enqueue(buffer[tid]);
}

// Объявляем CUDA-ядро для параллельного извлечения элементов из очереди
__global__ void queue_dequeue_kernel(Queue* queue, int* out, int N)
{
    // Вычисляем глобальный индекс текущего потока
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // Проверяем, что индекс не выходит за пределы обрабатываемого диапазона
    if (idx < N)
        // Извлекаем элемент из очереди и записываем его в выходной массив
        queue->dequeue(&out[idx]);
}

// =====================================
// Хост-функции для тестирования производительности
// =====================================

// Определяем функцию тестирования параллельного стека
void test_stack(int N, float& push_time_ms, float& pop_time_ms)
{
    // Объявляем указатель на буфер данных в памяти GPU
    int* d_buffer;

    // Объявляем указатель на выходной массив в памяти GPU
    int* d_out;

    // Объявляем указатель на структуру Stack в памяти GPU
    Stack* d_stack;

    // Выделяем память на GPU под массив данных
    CUDA_CHECK(cudaMalloc(&d_buffer, N * sizeof(int)));

    // Выделяем память на GPU под выходной массив
    CUDA_CHECK(cudaMalloc(&d_out, N * sizeof(int)));

    // Выделяем память на GPU под структуру Stack
    CUDA_CHECK(cudaMalloc(&d_stack, sizeof(Stack)));

    // Объявляем структуру Stack на стороне CPU
    Stack h_stack;

    // Инициализируем указатель на данные
    h_stack.data = d_buffer;

    // Инициализируем индекс вершины стека значением -1
    h_stack.top = -1;

    // Задаём ёмкость стека
    h_stack.capacity = N;

    // Копируем инициализированную структуру Stack из памяти CPU в память GPU
    CUDA_CHECK(cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice));

    // Объявляем события CUDA для измерения времени выполнения
    cudaEvent_t start, stop;

    // Создаём событие начала измерения времени
    cudaEventCreate(&start);

    // Создаём событие окончания измерения времени
    cudaEventCreate(&stop);

    // Регистрируем событие начала измерения времени
    cudaEventRecord(start);

    // Запускаем CUDA-ядро для параллельного добавления элементов в стек
    stack_push_kernel<<<(N + 255) / 256, 256>>>(d_stack, N);

    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);

    // Ожидаем завершения выполнения ядра
    cudaEventSynchronize(stop);

    // Вычисляем время выполнения операции добавления элементов в стек
    cudaEventElapsedTime(&push_time_ms, start, stop);

    // Регистрируем событие начала измерения времени для операции извлечения
    cudaEventRecord(start);

    // Запускаем CUDA-ядро для параллельного извлечения элементов из стека
    stack_pop_kernel<<<(N + 255) / 256, 256>>>(d_stack, d_out, N);

    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);

    // Ожидаем завершения выполнения ядра
    cudaEventSynchronize(stop);

    // Вычисляем время выполнения операции извлечения элементов из стека
    cudaEventElapsedTime(&pop_time_ms, start, stop);

    // Освобождаем память, выделенную под массив данных
    cudaFree(d_buffer);

    // Освобождаем память, выделенную под выходной массив
    cudaFree(d_out);

    // Освобождаем память, выделенную под структуру Stack
    cudaFree(d_stack);

    // Удаляем событие начала измерения времени
    cudaEventDestroy(start);

    // Удаляем событие окончания измерения времени
    cudaEventDestroy(stop);
}

// Определяем функцию тестирования параллельной очереди
void test_queue(int N, float& enqueue_time_ms, float& dequeue_time_ms)
{
    // Объявляем указатель на буфер данных в памяти GPU
    int* d_buffer;

    // Объявляем указатель на выходной массив в памяти GPU
    int* d_out;

    // Объявляем указатель на структуру Queue в памяти GPU
    Queue* d_queue;

    // Выделяем память на GPU под массив данных
    CUDA_CHECK(cudaMalloc(&d_buffer, N * sizeof(int)));

    // Выделяем память на GPU под выходной массив
    CUDA_CHECK(cudaMalloc(&d_out, N * sizeof(int)));

    // Выделяем память на GPU под структуру Queue
    CUDA_CHECK(cudaMalloc(&d_queue, sizeof(Queue)));

    // Объявляем структуру Queue на стороне CPU
    Queue h_queue;

    // Инициализируем указатель на данные
    h_queue.data = d_buffer;

    // Инициализируем индекс начала очереди
    h_queue.head = 0;

    // Инициализируем индекс конца очереди
    h_queue.tail = 0;

    // Задаём ёмкость очереди
    h_queue.capacity = N;

    // Копируем инициализированную структуру Queue из памяти CPU в память GPU
    CUDA_CHECK(cudaMemcpy(d_queue, &h_queue, sizeof(Queue), cudaMemcpyHostToDevice));

    // Объявляем события CUDA для измерения времени выполнения
    cudaEvent_t start, stop;

    // Создаём событие начала измерения времени
    cudaEventCreate(&start);

    // Создаём событие окончания измерения времени
    cudaEventCreate(&stop);

    // Регистрируем событие начала измерения времени для операции добавления
    cudaEventRecord(start);

    // Запускаем CUDA-ядро для параллельного добавления элементов в очередь
    queue_enqueue_kernel<<<(N + 255) / 256, 256>>>(d_queue, N);

    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);

    // Ожидаем завершения выполнения ядра
    cudaEventSynchronize(stop);

    // Вычисляем время выполнения операции добавления элементов в очередь
    cudaEventElapsedTime(&enqueue_time_ms, start, stop);

    // Регистрируем событие начала измерения времени для операции извлечения
    cudaEventRecord(start);

    // Запускаем CUDA-ядро для параллельного извлечения элементов из очереди
    queue_dequeue_kernel<<<(N + 255) / 256, 256>>>(d_queue, d_out, N);

    // Регистрируем событие окончания измерения времени
    cudaEventRecord(stop);

    // Ожидаем завершения выполнения ядра
    cudaEventSynchronize(stop);

    // Вычисляем время выполнения операции извлечения элементов из очереди
    cudaEventElapsedTime(&dequeue_time_ms, start, stop);

    // Освобождаем память, выделенную под массив данных
    cudaFree(d_buffer);

    // Освобождаем память, выделенную под выходной массив
    cudaFree(d_out);

    // Освобождаем память, выделенную под структуру Queue
    cudaFree(d_queue);

    // Удаляем событие начала измерения времени
    cudaEventDestroy(start);

    // Удаляем событие окончания измерения времени
    cudaEventDestroy(stop);
}
